This project uses machine learning to search for transiting exoplanets in planetary search surveys.
 Multiple neural networks (MLP, CNN, Wavelet MLP) are trained to recognize patterns from artificial light curves that mimic real observations. 
The trained networks are validated with real data using the known ephemerii of transiting planets discovered from the [Kepler](https://www.nasa.gov/mission_pages/kepler/main/index.html) mission.


## Getting started
It depends what you're interested in doing.. I would reccomend reading through the paper to get a general feel for what the code is doing. 
This particular machine learning algorithm is basically a glorified pattern recognition algorithm designed to recognize light curve shapes in photometric time series. 
I tried to include all of the relavant scripts that went into making this paper and their descriptions are below. 


## Comprehensive File Guide 
`generate_data.py` - generates over 300,000 training and test samples from the parameter space grid in Table 1.

`quasiperiodicity.py` - Generates the variability shape analysis plot (Figure 4)

`transit_shape_analysis.py` - Generates various figures showing how the light curve shape changes as a function of the planet and orbit parameters. This plot is particularly useful when creating training data sets for exoplanets because not all parameters are going to yield an observable signal (careful! if you're unfamiliar with transiting exoplanet geometry you could easily bias your training data)

`model_fit_history` - creation of each neural network and its training. The training performance per epoch is saved and used to create Figure 6. 

`ROC_auc_score.py` - Creates the receiver operating characteristic plot to assess the accuracy of each algorithm. 

`graph_featureloss.py` - Explorations into the accuracy of the neural network if we're missing input data (Figure 11)

`graph_interpolate.py` - One of my favorite plots because it shows the accuracy of each algorithm after a signal has been interpolated from either a high or low resolution state. This is particularly useful to understand because it will allow one to apply this algorithm to an arbitrary transit survey without needing to retrain the network. Instead, just transform the input data to match what the network needs. Since we're dealing with a time sorted signal we can get away with this for the most part. Just make sure the transit signal is greater than a few data points. 

`graph_sensitivity.py` - Explores how the detection accuracy of each algorithm changes with signal to noise ratio. 

`timeseries_eval.py` - a simple script that will evaluate a time series light curve that is larger than the input for the neural network by breaking it up into smaller lightcurves. Think of it like a sliding box-car evaluation along the light curve. 


## Citation
If you use any of these algorithms in your research please cite this github repository using the article below 

Pearson K. A., Palafox L., Griffith C. A., 2018, MNRAS, 474, 478

Here is an example bibtex
```
@ARTICLE{Pearson2018,
   author = {{Pearson}, K.~A. and {Palafox}, L. and {Griffith}, C.~A.},
    title = "{Searching for exoplanets using artificial intelligence}",
  journal = {\mnras},
archivePrefix = "arXiv",
   eprint = {1706.04319},
 primaryClass = "astro-ph.IM",
     year = 2018,
    month = feb,
   volume = 474,
    pages = {478-491},
      doi = {10.1093/mnras/stx2761},
   adsurl = {http://adsabs.harvard.edu/abs/2018MNRAS.474..478P},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
```

## Ways to improve the research 
This research was initially created for a class project and the field of machine learning is accelerating rapidly. 
I have a few suggestions on how to improve this research for future publications. 
Perhaps including some form of hyper-parameter optimization 
 The optimization of neural network architectures will be a standard in the future of machine learning algorithms. 
Using an attention map, to validate the algorithm is not overfitting the data.
 It basically determines what features from your input space are most relevant for the network to make a decision. 

Use a 2D CNN with phase folded light curves to detect periodic signals (think Period vs. Probability graph) where the input into the CNN would be a phase folded light curve stacked in an image like a 'water-fall' plot. Then the network outputs a probability for when the signal is in phase/aligned (i.e. correct period for phase fold). Training would consist of creating phase folded light curves at correct and incorrect periods. A positive detection would entail having an aligned signal (i.e. correct period) and vice versa for a negative detection. The power of a 2D CNN is that it will learn to correlate features in time and phase. This is particularly important because for a periodic signal, the data will be correlated in phase thus processing the signal should be done with convolutions. Since the data is already correlated in time and will be correlated in phase for the correct period, a 2D CNN is perfect to use.

Using this to detect Art planet transits in the next generation of transit survey. 

